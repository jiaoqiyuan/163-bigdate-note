## Azkaban插件加载流程

- executor在服务启动的时候会独立加载各个插件目录下的jar包

    - 插件根目录：azkaban.jobtype.plugin.dir=plugins/jobtypes

    - 根目录的一级子目录就是插件目录，插件名就是目录名

    - 每个插件会有独立的URLClassLoader来加载，其Parent ClassLoader是加载executor服务lib的ClassLoader

    - URLClassLoader需要配置加载的资源列表包括：插件目录下的jar、配置文件中指定的classpath目录下的文件

    - 根据插件配置文件中指定的jobtype.class，从URLClassLoader中拿到对应的class对象，缓存起来。

- 在具体job执行的时候，根据jobtype获取对应缓存的class对象，通过反射构建job对象执行对应的job。

## Azkaban插件-参数配置

- exec服务根据job的类型，构建对应的job对象。

- job执行的时候传入参数：jobid，sysProps，jobProps，log

- sysProps为系统参数，由管理员控制，用户不可见，不可设置。

- jobProps为job运行时参数，用户可配置。

- sysProps配置文件：commonprivate.properties和${jobtype-name}/private.properties，private.properties的优先级高于commonprivate.properties

- jobProps的配置文件exec/conf/global.properties, common.properties, ${jobtype-name}/plugin.properties, 项目包中的.properties文件，flowParameter（执行时配置参数），项目包中的.job文件。

    **JobProps配置文件优先级从低到高排序：**

    1. exec/conf/global.properties

    2. common.properties

    3. ${jobtype-name}/plugin.properties
    
    4. 项目包中的.properties文件

    5. flowParameter（执行时配置参数）

    6. 项目包中的.job文件

![azkaban_exec_job][1]

**Job实例根据传入的参数会进行安全性的验证，构建进程参数，然后拉起一个独立的java进程，在新的java进程中会调用用户的业务代码，运行业务逻辑。或者调用相关的大数据组件API，打包提交作业。**

**插件的部署除了部署jar，配置文件的部署也非常关键。**

## Azkaban插件-公共系统参数

公共系统参数在commonprivate.properties下，常用的配置项有：

- Hadoop安全性相关

    - Hadoop集群可以通过开启kerbours认证来提高安全性

        - kinit -kt {user}.keytab principal

    - 默认一个azkaban服务只对应一套hadoop/yarn集群

    - hadoop.security.manager.class：hadoop安全性管理类，如果是1.x版本配置azkaban.security.HadoopSecurityManager_H_1_0， 2.x版本配置azkaban.security.HadoopSecurityManager_H_2_0

    - proxy.keytab.location, proxy.user具有代理权限的keytab文件路径和principle

    - azkaban.should.proxy：是否需要以不同账户来执行hadoop任务，提交hadoop yarn任务的时候是否需要开启用户代理，如果开启任务代理，job进程将代理azkaban的登录账号来提交yarn任务，如果不开启将以executor的形式提交。

    - obtain.binary.taken：是否需要获取hadoop集群的token

    - obtain.namenode.token：是否需要获取namenode的token

    - obtain.jobtracker.token：是否需要获取jobtracker的token

    - 开启hadoop集群安全认证（kerbours）的例子：

        ```
        hadoop.security.manager.class=azkaban.security.HadoopSecurityManager_H_2_0
        proxy.keytab.location=/home/hadoop/azkaban.keytab
        klist -kt /home/hadoop/zakaban.keytab
        proxy.user=mapred/classb-bigdata4.server.163.org@TEST.HZ.NETEASE.COM
        azkaban.should.proxy=true
        obtain.binary.token=true
        obtain.namenode.token=true
        obtain.jobtracker.token=true
        ```

    - 不开启kerbours的例子：

        ```
        hadoop.security.manager.class=azkaban.security.HadoopSecurityManager_H_2_0
        azkaban.should.proxy=false
        ```

- JVM启动、Java Job进程参数

    - jobtype.golbal.classpath：类加载参数，全局job java进程classpath

        ```
        ${hadoop.home}/etc/hadoop,${hadoop.home}/share/hadoop/common/*,${hadoop.home}/share/hadoop/common/lib/*,${hadoop.home}/share/hadoop/hdfs/*, ${hadoop.home}/share/hadoop/hdfs/lib/*, ${hadoop.home}/share/hadoop/mapreduce/*, ${hadoop.home}/share/hadoop/mapreduce/lib/*, ${hadoop.home}/share/hadoop/yarn/*, ${hadoop.home}/share/hadoop/yarn/lib/*, ${hadoop.home}/share/hadoop/tools/lib/*
        ```

    - jobtype.golbal.jvm.args

        - 全局job java进程jvm启动参数

        - -Djava.library.path=${hadoop.home}/lib/native -Djava.io.tmpdir=/home/hadoop/tmp

- 底层组件Home路径

    - hadoop.home=/home/hadoop/hadoop-current

    - pig.home=pig_home

    - hive.home=/home/hadoop/hive

    - spark.home=spark_home

    - execute.as.user=false

    - azkaban.native.lib=

- 任务安全性相关参数

- 具体插件参数

    - hadoopjava

        - jobtype.class=azkaban.jobtype.HadoopJavaJob

    - Hive

        - jobtype.class=azkaban.jobtype.HadoopHiveJob

        - hive.aux.jar.path=${hive.home}/aux/lib

        - jobtype.classpath=${hive.home}/lib/*, ${hive.home}/conf, ${hive.aux.jar.path}

    - spark

        - jobtype.class=azkaban.jobtype.HadoopSparkJob

        - jobtype.classpath=${spark.home}/jars/*, ${spark.home}/conf





[1]: 